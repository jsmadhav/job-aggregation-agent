{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4fbc73",
   "metadata": {},
   "source": [
    "Agentic Frameworks for Job-Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890f4c5",
   "metadata": {},
   "source": [
    "The goal of this task is to perform a rapid agentic framework. Build a agent capable of extracting job posting information from several different company career pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f759dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet selenium langgraph pandas tqdm pydantic openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2d140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab90264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional, List, TypedDict, NotRequired\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import json, os, random, time, re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import cast\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "# No checkpointer for now to avoid thread_id requirements\n",
    "# from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Optional LLM normalizer (disabled by default)\n",
    "from openai import OpenAI  # not used unless USE_LLM=True\n",
    "\n",
    "# Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ---------- Config ----------\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "HEADLESS = True\n",
    "MAX_SCROLLS = 8\n",
    "SCROLL_PAUSE = 0.6  # slightly longer for stability\n",
    "\n",
    "USE_LLM = False\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def now_iso() -> str:\n",
    "    return datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
    "\n",
    "def get_origin(url: str) -> str:\n",
    "    p = urlparse(url)\n",
    "    return f\"{p.scheme}://{p.netloc}\"\n",
    "\n",
    "class JobRecordDict(TypedDict, total=False):\n",
    "    title: Optional[str]\n",
    "    location: Optional[str]\n",
    "    company: Optional[str]\n",
    "    application_link: Optional[str]\n",
    "    description_snippet: Optional[str]\n",
    "    source: Optional[str]\n",
    "    scraped_at: str\n",
    "\n",
    "# State typing: only `url` is required; the rest are NotRequired\n",
    "class ScrapeState(TypedDict):\n",
    "    url: str\n",
    "    limit: NotRequired[int]\n",
    "    site: NotRequired[str]\n",
    "    records: NotRequired[List[JobRecordDict]]\n",
    "    normalized: NotRequired[List[JobRecordDict]]\n",
    "    notes: NotRequired[List[str]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a26fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_driver() -> webdriver.Chrome:\n",
    "    ua = random.choice(USER_AGENTS)\n",
    "    opts = Options()\n",
    "    if HEADLESS:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--window-size=1280,2000\")\n",
    "    opts.add_argument(f\"user-agent={ua}\")\n",
    "    return webdriver.Chrome(options=opts)\n",
    "\n",
    "def open_and_render(driver: webdriver.Chrome, url: str, wait_css: Optional[str]=None, timeout: int=30):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        if wait_css:\n",
    "            WebDriverWait(driver, timeout).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, wait_css))\n",
    "            )\n",
    "    except Exception:\n",
    "        # surface a hint for debugging\n",
    "        print(f\"[open_and_render] Timed out waiting for: {wait_css}\")\n",
    "\n",
    "def try_dismiss_overlays(driver: webdriver.Chrome):\n",
    "    \"\"\"Best-effort: dismiss cookie/consent banners that block content.\"\"\"\n",
    "    xpaths = [\n",
    "        \"//button[contains(., 'Accept all')]\",\n",
    "        \"//button[contains(., 'I agree')]\",\n",
    "        \"//button[contains(., 'Accept')]\",\n",
    "        \"//button[contains(., 'Got it')]\",\n",
    "        \"//button[contains(., 'OK')]\",\n",
    "        \"//div[@role='dialog']//button[contains(., 'Accept')]\",\n",
    "    ]\n",
    "    for xp in xpaths:\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, xp)))\n",
    "            btn.click()\n",
    "            time.sleep(0.3)\n",
    "        except Exception:\n",
    "            pass  # ignore if not present\n",
    "\n",
    "def infinite_scroll(driver: webdriver.Chrome, max_scrolls: int=MAX_SCROLLS, pause: float=SCROLL_PAUSE):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(max_scrolls):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(pause)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebda3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_site(url: str) -> str:\n",
    "    u = url.lower()\n",
    "    if \"careers.google.com\" in u:\n",
    "        return \"google\"\n",
    "    if \"metacareers.com\" in u or \"facebookcareers\" in u:\n",
    "        return \"meta\"\n",
    "    if \"boards.greenhouse.io\" in u:\n",
    "        return \"greenhouse\"\n",
    "    return \"generic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d941780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_google_with_selenium(driver: webdriver.Chrome, limit: int = 25) -> List[JobRecordDict]:\n",
    "    anchors = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/jobs/results/']\")\n",
    "    out: List[JobRecordDict] = []\n",
    "    seen = set()\n",
    "    for a in anchors:\n",
    "        title = (a.text or \"\").strip()\n",
    "        link = a.get_attribute(\"href\")\n",
    "        if not link:\n",
    "            continue\n",
    "        key = (title, link)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        loc = None\n",
    "        try:\n",
    "            parent = a.find_element(By.XPATH, \"./ancestor-or-self::*[1]\")\n",
    "            loc_el = parent.find_elements(By.CSS_SELECTOR, \"[data-test*='locations'], [class*='location'], .place\")\n",
    "            if loc_el:\n",
    "                loc = (loc_el[0].text or \"\").strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        rec: JobRecordDict = {\n",
    "            \"title\": title or None,\n",
    "            \"location\": loc or None,\n",
    "            \"company\": \"Google\",\n",
    "            \"application_link\": link,\n",
    "        }\n",
    "        out.append(rec)\n",
    "        if len(out) >= limit:\n",
    "            break\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ac4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_meta_with_selenium(driver: webdriver.Chrome, limit: int = 25) -> List[JobRecordDict]:\n",
    "    anchors = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/jobs/']\")\n",
    "    out: List[JobRecordDict] = []\n",
    "    seen = set()\n",
    "    for a in anchors:\n",
    "        link = a.get_attribute(\"href\")\n",
    "        if not link:\n",
    "            continue\n",
    "        title = (a.text or \"\").strip()\n",
    "        if not title:\n",
    "            try:\n",
    "                h = a.find_element(By.CSS_SELECTOR, \"h2, h3\")\n",
    "                title = h.text.strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        loc = None\n",
    "        try:\n",
    "            loc_el = a.find_elements(By.CSS_SELECTOR, \"[data-testid*='job-location'], [class*='location']\")\n",
    "            if loc_el:\n",
    "                loc = (loc_el[0].text or \"\").strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        key = (title, link)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        rec: JobRecordDict = {\n",
    "            \"title\": title or None,\n",
    "            \"location\": loc or None,\n",
    "            \"company\": \"Meta\",\n",
    "            \"application_link\": link,\n",
    "        }\n",
    "        out.append(rec)\n",
    "        if len(out) >= limit:\n",
    "            break\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c295485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_greenhouse_with_selenium(driver: webdriver.Chrome, limit: int = 25) -> List[JobRecordDict]:\n",
    "    anchors = driver.find_elements(By.CSS_SELECTOR, \"div.opening a, section#jobs a[href*='/jobs/']\")\n",
    "    out: List[JobRecordDict] = []\n",
    "    seen = set()\n",
    "    for a in anchors:\n",
    "        title = (a.text or \"\").strip()\n",
    "        link = a.get_attribute(\"href\")\n",
    "        if not link:\n",
    "            continue\n",
    "\n",
    "        loc = None\n",
    "        try:\n",
    "            sibs = a.find_elements(By.XPATH, \"following-sibling::*[1]\")\n",
    "            if sibs:\n",
    "                loc = (sibs[0].text or \"\").strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        key = (title, link)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        rec: JobRecordDict = {\n",
    "            \"title\": title or None,\n",
    "            \"location\": loc or None,\n",
    "            \"company\": None,\n",
    "            \"application_link\": link,\n",
    "        }\n",
    "        out.append(rec)\n",
    "        if len(out) >= limit:\n",
    "            break\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c474a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_generic_with_selenium(driver: webdriver.Chrome, limit: int = 25) -> List[JobRecordDict]:\n",
    "    anchors = driver.find_elements(By.CSS_SELECTOR, \"a[href*='job'], a[href*='/jobs/'], a[href*='careers']\")\n",
    "    out: List[JobRecordDict] = []\n",
    "    seen = set()\n",
    "    for a in anchors:\n",
    "        title = (a.text or \"\").strip()\n",
    "        link = a.get_attribute(\"href\")\n",
    "        if not link:\n",
    "            continue\n",
    "        if not title or len(title.split()) > 15:\n",
    "            continue\n",
    "\n",
    "        key = (title, link)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        rec: JobRecordDict = {\n",
    "            \"title\": title,\n",
    "            \"location\": None,\n",
    "            \"company\": None,\n",
    "            \"application_link\": link,\n",
    "        }\n",
    "        out.append(rec)\n",
    "        if len(out) >= limit:\n",
    "            break\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170fd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESC_SELECTORS = [\n",
    "    \"section\", \"article\", \"[data-test*='description']\",\n",
    "    \".job-description\", \"#job-details\", \".section\"\n",
    "]\n",
    "\n",
    "def resolve_description_with_selenium(url: Optional[str], max_len: int=800) -> Optional[str]:\n",
    "    if not url:\n",
    "        return None\n",
    "    drv = make_driver()\n",
    "    try:\n",
    "        open_and_render(drv, url, wait_css=None, timeout=15)\n",
    "        try_dismiss_overlays(drv)\n",
    "        for css in DESC_SELECTORS:\n",
    "            try:\n",
    "                el = drv.find_element(By.CSS_SELECTOR, css)\n",
    "                txt = (el.text or \"\").strip()\n",
    "                if txt:\n",
    "                    return txt[:max_len]\n",
    "            except Exception:\n",
    "                continue\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "    finally:\n",
    "        drv.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742535dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_detect(state: ScrapeState) -> ScrapeState:\n",
    "    url = state.get(\"url\")\n",
    "    if not url:\n",
    "        raise ValueError(\"State missing required key: 'url'\")\n",
    "\n",
    "    site = detect_site(url)\n",
    "\n",
    "    # cast so Pylance knows this dict is a ScrapeState\n",
    "    new = cast(ScrapeState, dict(state))\n",
    "    new[\"site\"] = site\n",
    "\n",
    "    notes = list(new.get(\"notes\", []))\n",
    "    notes.append(f\"Detected site: {site}\")\n",
    "    new[\"notes\"] = notes\n",
    "    return new\n",
    "\n",
    "from typing import cast, List  # make sure this import is present\n",
    "\n",
    "def node_parse(state: ScrapeState) -> ScrapeState:\n",
    "    url = state.get(\"url\")\n",
    "    if not url:\n",
    "        raise ValueError(\"State missing required key: 'url'\")\n",
    "\n",
    "    limit = state.get(\"limit\", 25)\n",
    "    site = state.get(\"site\", \"generic\")\n",
    "\n",
    "    wait_map = {\n",
    "        \"google\": \"a[href*='/jobs/results/']\",\n",
    "        \"meta\": \"a[href*='/jobs/']\",\n",
    "        \"greenhouse\": \"section#jobs a, div.opening a\",\n",
    "        \"generic\": \"a\",\n",
    "    }\n",
    "\n",
    "    drv = make_driver()\n",
    "    rows: List[JobRecordDict] = []   # <-- initialize with correct type\n",
    "\n",
    "    try:\n",
    "        open_and_render(drv, url, wait_css=wait_map.get(site, \"a\"), timeout=30)\n",
    "        try_dismiss_overlays(drv)\n",
    "        infinite_scroll(drv)\n",
    "\n",
    "        if site == \"google\":\n",
    "            rows = parse_google_with_selenium(drv, limit=limit)\n",
    "        elif site == \"meta\":\n",
    "            rows = parse_meta_with_selenium(drv, limit=limit)\n",
    "        elif site == \"greenhouse\":\n",
    "            rows = parse_greenhouse_with_selenium(drv, limit=limit)\n",
    "        else:\n",
    "            rows = parse_generic_with_selenium(drv, limit=limit)\n",
    "    finally:\n",
    "        drv.quit()\n",
    "\n",
    "    new = cast(ScrapeState, dict(state))\n",
    "    new[\"records\"] = rows\n",
    "\n",
    "    notes = list(new.get(\"notes\", []))\n",
    "    notes.append(f\"Parsed {len(rows)} rows\")\n",
    "    new[\"notes\"] = notes\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8be51bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, cast\n",
    "\n",
    "def node_enrich(state: ScrapeState) -> ScrapeState:\n",
    "    \"\"\"\n",
    "    Enrich each parsed row by visiting the job page and extracting a short description.\n",
    "    Requires:\n",
    "      - resolve_description_with_selenium(url: Optional[str]) -> Optional[str]\n",
    "      - now_iso() -> str\n",
    "      - JobRecordDict, ScrapeState TypedDicts\n",
    "    \"\"\"\n",
    "    url = state.get(\"url\", \"\")\n",
    "    rows: List[JobRecordDict] = state.get(\"records\", []) or []\n",
    "\n",
    "    out: List[JobRecordDict] = []\n",
    "    for r in tqdm(rows, desc=\"Resolving details\"):\n",
    "        desc = resolve_description_with_selenium(r.get(\"application_link\"))\n",
    "\n",
    "        rec: JobRecordDict = {\n",
    "            \"title\": r.get(\"title\"),\n",
    "            \"location\": r.get(\"location\"),\n",
    "            \"company\": r.get(\"company\"),\n",
    "            \"application_link\": r.get(\"application_link\"),\n",
    "            \"description_snippet\": desc,\n",
    "            \"source\": url,\n",
    "            \"scraped_at\": now_iso(),\n",
    "        }\n",
    "        out.append(rec)\n",
    "\n",
    "    new = cast(ScrapeState, dict(state))   # tell Pylance this dict conforms to ScrapeState\n",
    "    new[\"records\"] = out\n",
    "\n",
    "    notes = list(new.get(\"notes\", []))\n",
    "    notes.append(\"Enriched with description snippets\")\n",
    "    new[\"notes\"] = notes\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53ae932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a data normalizer.\n",
    "Normalize 'title' and 'location' to concise standardized forms. Do not invent values.\n",
    "Keep other fields unchanged. If missing, leave as null.\n",
    "Return JSON list with the same keys.\n",
    "\"\"\"\n",
    "\n",
    "def _client_or_none():\n",
    "    key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not key:\n",
    "        return None\n",
    "    try:\n",
    "        return OpenAI(api_key=key)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _strip_code_fence(text: str) -> str:\n",
    "    t = text.strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = t.strip(\"`\")\n",
    "        # After stripping backticks, it may start with 'json\\n'\n",
    "        t = re.sub(r\"^json\\s*\", \"\", t, flags=re.IGNORECASE)\n",
    "    return t.strip()\n",
    "\n",
    "def node_normalize_llm(state: ScrapeState) -> ScrapeState:\n",
    "    if not USE_LLM:\n",
    "        new = cast(ScrapeState, dict(state))\n",
    "        new[\"normalized\"] = state.get(\"records\", [])\n",
    "        notes = list(new.get(\"notes\", []))\n",
    "        notes.append(\"LLM normalization skipped (USE_LLM=False)\")\n",
    "        new[\"notes\"] = notes\n",
    "        return new\n",
    "\n",
    "    client = _client_or_none()\n",
    "    if client is None:\n",
    "        new = cast(ScrapeState, dict(state))\n",
    "        new[\"normalized\"] = state.get(\"records\", [])\n",
    "        notes = list(new.get(\"notes\", []))\n",
    "        notes.append(\"LLM normalization skipped (no OPENAI_API_KEY)\")\n",
    "        new[\"notes\"] = notes\n",
    "        return new\n",
    "\n",
    "    records = state.get(\"records\", [])\n",
    "    content = json.dumps(records, ensure_ascii=False)\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"Normalize these records and return JSON only:\\n{content}\"}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        txt = resp.choices[0].message.content or \"[]\"\n",
    "        txt = _strip_code_fence(txt)\n",
    "        normalized = json.loads(txt)\n",
    "    except Exception:\n",
    "        normalized = records\n",
    "\n",
    "    new = cast(ScrapeState, dict(state))\n",
    "    new[\"normalized\"] = normalized\n",
    "    notes = list(new.get(\"notes\", []))\n",
    "    notes.append(\"Applied LLM normalizer\" if normalized is not records else \"LLM normalizer failed; passthrough\")\n",
    "    new[\"notes\"] = notes\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0783ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph (Selenium) pipeline ready.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/IPython/core/formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/langgraph/pregel/main.py:758\u001b[39m, in \u001b[36mPregel._repr_mimebundle_\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    755\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Mime bundle used by Jupyter to display the graph\"\"\"\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    757\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext/plain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    759\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/langchain_core/runnables/graph.py:702\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m    693\u001b[39m     draw_mermaid_png,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    696\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    697\u001b[39m     curve_style=curve_style,\n\u001b[32m    698\u001b[39m     node_colors=node_colors,\n\u001b[32m    699\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    700\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    701\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/langchain_core/runnables/graph_mermaid.py:310\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    304\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    305\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    306\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    307\u001b[39m         )\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    318\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/langchain_core/runnables/graph_mermaid.py:463\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    458\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    459\u001b[39m     msg = (\n\u001b[32m    460\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    462\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    467\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x112246660>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No checkpointer to keep it simple\n",
    "graph = StateGraph(ScrapeState)\n",
    "graph.add_node(\"detect\", node_detect)\n",
    "graph.add_node(\"parse\", node_parse)\n",
    "graph.add_node(\"enrich\", node_enrich)\n",
    "\n",
    "graph.set_entry_point(\"detect\")\n",
    "graph.add_edge(\"detect\", \"parse\")\n",
    "graph.add_edge(\"parse\", \"enrich\")\n",
    "graph.add_edge(\"enrich\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "print(\"LangGraph (Selenium) pipeline ready.\")\n",
    "app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f26f8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scrape(url: str, limit: int=10):\n",
    "    final = app.invoke({\"url\": url, \"limit\": limit})\n",
    "    rows = final.get(\"records\") or []\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"[run_scrape] Empty results — check console counts above and consider increasing MAX_SCROLLS.\")\n",
    "    return final, df\n",
    "\n",
    "def export_json(records: List[dict], path: str) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Wrote {len(records)} records to {path}\")\n",
    "\n",
    "def export_csv(records: List[dict], path: str) -> None:\n",
    "    if not records:\n",
    "        print(\"No records to export.\")\n",
    "        return\n",
    "    pd.DataFrame(records).to_csv(path, index=False)\n",
    "    print(f\"Wrote {len(records)} records to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28dcf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving details:   0%|          | 0/10 [00:00<?, ?it/s]/var/folders/h9/dl51wvrn3gx81mp982hlcc_r0000gn/T/ipykernel_914/2663807239.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
      "Resolving details: 100%|██████████| 10/10 [02:24<00:00, 14.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>application_link</th>\n",
       "      <th>description_snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>scraped_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software Engineer, Machine Learning\\nSunnyvale...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/1436181490732782</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs</td>\n",
       "      <td>2025-09-24T04:04:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Software Engineer, Infrastructure\\nSunnyvale, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/677160418622314</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs</td>\n",
       "      <td>2025-09-24T04:05:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Design Engineer\\nSunnyvale, CA +3 loca...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/1092822929374881</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs</td>\n",
       "      <td>2025-09-24T04:05:15Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Scientist Intern, AI &amp; System Co-Desi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/1859723961565682</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs</td>\n",
       "      <td>2025-09-24T04:05:30Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wireless - Embedded HW Connectivity Engineer\\n...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/2540883539615658</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs</td>\n",
       "      <td>2025-09-24T04:05:45Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title location company  \\\n",
       "0  Software Engineer, Machine Learning\\nSunnyvale...     None    Meta   \n",
       "1  Software Engineer, Infrastructure\\nSunnyvale, ...     None    Meta   \n",
       "2  Product Design Engineer\\nSunnyvale, CA +3 loca...     None    Meta   \n",
       "3  Research Scientist Intern, AI & System Co-Desi...     None    Meta   \n",
       "4  Wireless - Embedded HW Connectivity Engineer\\n...     None    Meta   \n",
       "\n",
       "                                    application_link description_snippet  \\\n",
       "0  https://www.metacareers.com/jobs/1436181490732782                None   \n",
       "1   https://www.metacareers.com/jobs/677160418622314                None   \n",
       "2  https://www.metacareers.com/jobs/1092822929374881                None   \n",
       "3  https://www.metacareers.com/jobs/1859723961565682                None   \n",
       "4  https://www.metacareers.com/jobs/2540883539615658                None   \n",
       "\n",
       "                             source            scraped_at  \n",
       "0  https://www.metacareers.com/jobs  2025-09-24T04:04:46Z  \n",
       "1  https://www.metacareers.com/jobs  2025-09-24T04:05:01Z  \n",
       "2  https://www.metacareers.com/jobs  2025-09-24T04:05:15Z  \n",
       "3  https://www.metacareers.com/jobs  2025-09-24T04:05:30Z  \n",
       "4  https://www.metacareers.com/jobs  2025-09-24T04:05:45Z  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes:\n",
      " - Detected site: meta\n",
      " - Parsed 10 rows\n",
      " - Enriched with description snippets\n"
     ]
    }
   ],
   "source": [
    "final, df = run_scrape(\"https://www.metacareers.com/jobs\", limit=10)\n",
    "display(df.head())\n",
    "print(\"\\nNotes:\", *final.get(\"notes\", []), sep=\"\\n - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eefdf45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving details:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\madha\\AppData\\Local\\Temp\\ipykernel_39572\\2663807239.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
      "Resolving details: 100%|██████████| 10/10 [03:08<00:00, 18.82s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "application_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description_snippet",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scraped_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a8ca2661-867c-4cf3-b2e2-9b209d4e7d7b",
       "rows": [
        [
         "0",
         "Data Analyst - People Analytics\nAustin, TX +2 locations\n•\nData & Analytics\n•\nHR\nMultiple Locations\nData & Analytics\nHR",
         null,
         "Meta",
         "https://www.metacareers.com/jobs/1124394892922401",
         null,
         "https://www.metacareers.com/jobs?q=data%20analyst",
         "2025-09-03T15:28:39Z"
        ],
        [
         "1",
         "Global Operations Data Analyst\nDublin, Ireland +1 locations\n•\nGlobal Operations\n•\nOperations\nMultiple Locations\nGlobal Operations\nOperations",
         null,
         "Meta",
         "https://www.metacareers.com/jobs/796191043363303",
         null,
         "https://www.metacareers.com/jobs?q=data%20analyst",
         "2025-09-03T15:28:58Z"
        ],
        [
         "2",
         "Data Management Analyst (Short Term Employee)\nAustin, TX +2 locations\n•\nPeople & Recruiting\n•\nAnalytics\nMultiple Locations\nPeople & Recruiting\nAnalytics",
         null,
         "Meta",
         "https://www.metacareers.com/jobs/693648076696098",
         null,
         "https://www.metacareers.com/jobs?q=data%20analyst",
         "2025-09-03T15:29:16Z"
        ],
        [
         "3",
         "Data Analyst\nMenlo Park, CA\n•\nData & Analytics\n•\nAnalytics\nMenlo Park, CA\nData & Analytics\nAnalytics",
         null,
         "Meta",
         "https://www.metacareers.com/jobs/1851270308789075",
         null,
         "https://www.metacareers.com/jobs?q=data%20analyst",
         "2025-09-03T15:29:34Z"
        ],
        [
         "4",
         "Infrastructure Market Research Analyst\nWashington, DC +1 locations\n•\nData Center +1 more\n•\nData Center Strategy\nMultiple Locations\nData Center\nInfrastructure\nData Center Strategy",
         null,
         "Meta",
         "https://www.metacareers.com/jobs/720998080830793",
         null,
         "https://www.metacareers.com/jobs?q=data%20analyst",
         "2025-09-03T15:29:53Z"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>application_link</th>\n",
       "      <th>description_snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>scraped_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - People Analytics\\nAustin, TX +2...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/1124394892922401</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs?q=data%20analyst</td>\n",
       "      <td>2025-09-03T15:28:39Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global Operations Data Analyst\\nDublin, Irelan...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/796191043363303</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs?q=data%20analyst</td>\n",
       "      <td>2025-09-03T15:28:58Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Management Analyst (Short Term Employee)\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/693648076696098</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs?q=data%20analyst</td>\n",
       "      <td>2025-09-03T15:29:16Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst\\nMenlo Park, CA\\n•\\nData &amp; Analyt...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/1851270308789075</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs?q=data%20analyst</td>\n",
       "      <td>2025-09-03T15:29:34Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infrastructure Market Research Analyst\\nWashin...</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://www.metacareers.com/jobs/720998080830793</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.metacareers.com/jobs?q=data%20analyst</td>\n",
       "      <td>2025-09-03T15:29:53Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title location company  \\\n",
       "0  Data Analyst - People Analytics\\nAustin, TX +2...     None    Meta   \n",
       "1  Global Operations Data Analyst\\nDublin, Irelan...     None    Meta   \n",
       "2  Data Management Analyst (Short Term Employee)\\...     None    Meta   \n",
       "3  Data Analyst\\nMenlo Park, CA\\n•\\nData & Analyt...     None    Meta   \n",
       "4  Infrastructure Market Research Analyst\\nWashin...     None    Meta   \n",
       "\n",
       "                                    application_link description_snippet  \\\n",
       "0  https://www.metacareers.com/jobs/1124394892922401                None   \n",
       "1   https://www.metacareers.com/jobs/796191043363303                None   \n",
       "2   https://www.metacareers.com/jobs/693648076696098                None   \n",
       "3  https://www.metacareers.com/jobs/1851270308789075                None   \n",
       "4   https://www.metacareers.com/jobs/720998080830793                None   \n",
       "\n",
       "                                              source            scraped_at  \n",
       "0  https://www.metacareers.com/jobs?q=data%20analyst  2025-09-03T15:28:39Z  \n",
       "1  https://www.metacareers.com/jobs?q=data%20analyst  2025-09-03T15:28:58Z  \n",
       "2  https://www.metacareers.com/jobs?q=data%20analyst  2025-09-03T15:29:16Z  \n",
       "3  https://www.metacareers.com/jobs?q=data%20analyst  2025-09-03T15:29:34Z  \n",
       "4  https://www.metacareers.com/jobs?q=data%20analyst  2025-09-03T15:29:53Z  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes:\n",
      " - Detected site: meta\n",
      " - Parsed 10 rows\n",
      " - Enriched with description snippets\n"
     ]
    }
   ],
   "source": [
    "final, df = run_scrape(\"https://www.metacareers.com/jobs?q=data%20analyst\", limit=10)\n",
    "display(df.head())\n",
    "print(\"\\nNotes:\", *final.get(\"notes\", []), sep=\"\\n - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0499109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving details:   0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\madha\\AppData\\Local\\Temp\\ipykernel_39572\\2663807239.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
      "Resolving details: 100%|██████████| 20/20 [05:58<00:00, 17.92s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "application_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description_snippet",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scraped_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "74ef0c89-08fc-4f69-99c2-c1dd23c03817",
       "rows": [
        [
         "0",
         "Medical Records Specialist, Amazon One Medical Customer Care",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/2889177/medical-records-specialist-amazon-one-medical-customer-care",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T15:58:46Z"
        ],
        [
         "1",
         "...Read more",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/2889177/medical-records-specialist-amazon-one-medical-customer-care",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T15:59:04Z"
        ],
        [
         "2",
         "Executive Assistant, Devices & Services Design",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/3063086/executive-assistant-devices-services-design",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T15:59:21Z"
        ],
        [
         "3",
         "...Read more",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/3063086/executive-assistant-devices-services-design",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T15:59:38Z"
        ],
        [
         "4",
         "Site Marketing Manager , Zappos FBA",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/3051114/site-marketing-manager-zappos-fba",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T15:59:55Z"
        ],
        [
         "5",
         "...Read more",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/3051114/site-marketing-manager-zappos-fba",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T16:00:12Z"
        ],
        [
         "6",
         "Senior UX Designer, Digital Acceleration",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/2985608/senior-ux-designer-digital-acceleration",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T16:00:29Z"
        ],
        [
         "7",
         "...Read more",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/2985608/senior-ux-designer-digital-acceleration",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T16:00:46Z"
        ],
        [
         "8",
         "Applied Scientist, AGI Foundational Modeling - Speech",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/3006856/applied-scientist-agi-foundational-modeling-speech",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T16:01:05Z"
        ],
        [
         "9",
         "...Read more",
         null,
         null,
         "https://www.amazon.jobs/en/jobs/3006856/applied-scientist-agi-foundational-modeling-speech",
         null,
         "https://www.amazon.jobs/en/search?base",
         "2025-09-03T16:01:27Z"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>application_link</th>\n",
       "      <th>description_snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>scraped_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medical Records Specialist, Amazon One Medical...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/2889177/medica...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T15:58:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...Read more</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/2889177/medica...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T15:59:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Executive Assistant, Devices &amp; Services Design</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/3063086/execut...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T15:59:21Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...Read more</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/3063086/execut...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T15:59:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Site Marketing Manager , Zappos FBA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/3051114/site-m...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T15:59:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...Read more</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/3051114/site-m...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T16:00:12Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior UX Designer, Digital Acceleration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/2985608/senior...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T16:00:29Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>...Read more</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/2985608/senior...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T16:00:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Applied Scientist, AGI Foundational Modeling -...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/3006856/applie...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T16:01:05Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>...Read more</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/jobs/3006856/applie...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazon.jobs/en/search?base</td>\n",
       "      <td>2025-09-03T16:01:27Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title location company  \\\n",
       "0  Medical Records Specialist, Amazon One Medical...     None    None   \n",
       "1                                       ...Read more     None    None   \n",
       "2     Executive Assistant, Devices & Services Design     None    None   \n",
       "3                                       ...Read more     None    None   \n",
       "4                Site Marketing Manager , Zappos FBA     None    None   \n",
       "5                                       ...Read more     None    None   \n",
       "6           Senior UX Designer, Digital Acceleration     None    None   \n",
       "7                                       ...Read more     None    None   \n",
       "8  Applied Scientist, AGI Foundational Modeling -...     None    None   \n",
       "9                                       ...Read more     None    None   \n",
       "\n",
       "                                    application_link description_snippet  \\\n",
       "0  https://www.amazon.jobs/en/jobs/2889177/medica...                None   \n",
       "1  https://www.amazon.jobs/en/jobs/2889177/medica...                None   \n",
       "2  https://www.amazon.jobs/en/jobs/3063086/execut...                None   \n",
       "3  https://www.amazon.jobs/en/jobs/3063086/execut...                None   \n",
       "4  https://www.amazon.jobs/en/jobs/3051114/site-m...                None   \n",
       "5  https://www.amazon.jobs/en/jobs/3051114/site-m...                None   \n",
       "6  https://www.amazon.jobs/en/jobs/2985608/senior...                None   \n",
       "7  https://www.amazon.jobs/en/jobs/2985608/senior...                None   \n",
       "8  https://www.amazon.jobs/en/jobs/3006856/applie...                None   \n",
       "9  https://www.amazon.jobs/en/jobs/3006856/applie...                None   \n",
       "\n",
       "                                   source            scraped_at  \n",
       "0  https://www.amazon.jobs/en/search?base  2025-09-03T15:58:46Z  \n",
       "1  https://www.amazon.jobs/en/search?base  2025-09-03T15:59:04Z  \n",
       "2  https://www.amazon.jobs/en/search?base  2025-09-03T15:59:21Z  \n",
       "3  https://www.amazon.jobs/en/search?base  2025-09-03T15:59:38Z  \n",
       "4  https://www.amazon.jobs/en/search?base  2025-09-03T15:59:55Z  \n",
       "5  https://www.amazon.jobs/en/search?base  2025-09-03T16:00:12Z  \n",
       "6  https://www.amazon.jobs/en/search?base  2025-09-03T16:00:29Z  \n",
       "7  https://www.amazon.jobs/en/search?base  2025-09-03T16:00:46Z  \n",
       "8  https://www.amazon.jobs/en/search?base  2025-09-03T16:01:05Z  \n",
       "9  https://www.amazon.jobs/en/search?base  2025-09-03T16:01:27Z  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes:\n",
      " - Detected site: generic\n",
      " - Parsed 20 rows\n",
      " - Enriched with description snippets\n"
     ]
    }
   ],
   "source": [
    "final, df = run_scrape(\"https://www.amazon.jobs/en/search?base\", limit=20)\n",
    "display(df.head(10))\n",
    "print(\"\\nNotes:\", *final.get(\"notes\", []), sep=\"\\n - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3455ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving details:   0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\madha\\AppData\\Local\\Temp\\ipykernel_39572\\2663807239.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
      "Resolving details: 100%|██████████| 4/4 [01:15<00:00, 18.77s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "application_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description_snippet",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scraped_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ecfc5985-780b-4895-88af-e926ee2a8cef",
       "rows": [
        [
         "0",
         "Netflix’s culture",
         null,
         null,
         "https://jobs.netflix.com/culture",
         null,
         "https://explore.jobs.netflix.net/careers",
         "2025-09-03T16:07:33Z"
        ],
        [
         "1",
         "Netflix House",
         null,
         null,
         "https://apply.netflixhouse.com/careers",
         null,
         "https://explore.jobs.netflix.net/careers",
         "2025-09-03T16:07:52Z"
        ],
        [
         "2",
         "Privacy",
         null,
         null,
         "https://jobs.netflix.com/candidate-privacy",
         null,
         "https://explore.jobs.netflix.net/careers",
         "2025-09-03T16:08:11Z"
        ],
        [
         "3",
         "Do Not Sell Or Share My Personal Information",
         null,
         null,
         "https://jobs.netflix.com/dnssi",
         null,
         "https://explore.jobs.netflix.net/careers",
         "2025-09-03T16:08:30Z"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>application_link</th>\n",
       "      <th>description_snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>scraped_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix’s culture</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://jobs.netflix.com/culture</td>\n",
       "      <td>None</td>\n",
       "      <td>https://explore.jobs.netflix.net/careers</td>\n",
       "      <td>2025-09-03T16:07:33Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netflix House</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://apply.netflixhouse.com/careers</td>\n",
       "      <td>None</td>\n",
       "      <td>https://explore.jobs.netflix.net/careers</td>\n",
       "      <td>2025-09-03T16:07:52Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Privacy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://jobs.netflix.com/candidate-privacy</td>\n",
       "      <td>None</td>\n",
       "      <td>https://explore.jobs.netflix.net/careers</td>\n",
       "      <td>2025-09-03T16:08:11Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do Not Sell Or Share My Personal Information</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://jobs.netflix.com/dnssi</td>\n",
       "      <td>None</td>\n",
       "      <td>https://explore.jobs.netflix.net/careers</td>\n",
       "      <td>2025-09-03T16:08:30Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title location company  \\\n",
       "0                             Netflix’s culture     None    None   \n",
       "1                                 Netflix House     None    None   \n",
       "2                                       Privacy     None    None   \n",
       "3  Do Not Sell Or Share My Personal Information     None    None   \n",
       "\n",
       "                             application_link description_snippet  \\\n",
       "0            https://jobs.netflix.com/culture                None   \n",
       "1      https://apply.netflixhouse.com/careers                None   \n",
       "2  https://jobs.netflix.com/candidate-privacy                None   \n",
       "3              https://jobs.netflix.com/dnssi                None   \n",
       "\n",
       "                                     source            scraped_at  \n",
       "0  https://explore.jobs.netflix.net/careers  2025-09-03T16:07:33Z  \n",
       "1  https://explore.jobs.netflix.net/careers  2025-09-03T16:07:52Z  \n",
       "2  https://explore.jobs.netflix.net/careers  2025-09-03T16:08:11Z  \n",
       "3  https://explore.jobs.netflix.net/careers  2025-09-03T16:08:30Z  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes:\n",
      " - Detected site: generic\n",
      " - Parsed 4 rows\n",
      " - Enriched with description snippets\n"
     ]
    }
   ],
   "source": [
    "final, df = run_scrape(\"https://explore.jobs.netflix.net/careers\", limit = 10)\n",
    "display(df.head())\n",
    "print(\"\\nNotes:\", *final.get(\"notes\", []), sep=\"\\n - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "509a964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving details:   0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\madha\\AppData\\Local\\Temp\\ipykernel_39572\\2663807239.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
      "Resolving details: 100%|██████████| 4/4 [01:47<00:00, 26.92s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "application_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description_snippet",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scraped_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a47f90cc-3a69-42cd-9095-a5afece1b026",
       "rows": [
        [
         "0",
         "contact us.",
         null,
         null,
         "https://www.amazondelivers.jobs/contactus",
         null,
         "https://hiring.amazon.com/%22",
         "2025-09-05T15:06:04Z"
        ],
        [
         "1",
         "instagraminstagram",
         null,
         null,
         "https://www.instagram.com/amazonjobs/",
         "Log In\nSign Up\namazonjobs\nAmazon Jobs\n153 posts\n96.7K followers\n112 following\nOfficial Instagram for Amazon Hourly Opportunities. Find hourly roles near you in the link below.\nHow To Apply\nAdvice\nAccommodations\nReferrals 💰\nApply Now\nBenefits\nMilitary\nCareer Choice\nShow more posts from amazonjobs\nRelated accounts\nSee all\nsellonamazon\nSell on Amazon\nFollow\namazonads\nAmazon Ads\nFollow\nadecco_canada\nAdecco Canada\nFollow\namazonastro\nAmazon Astro\nFollow\nsalesforcejobs\nSalesforce Careers\nFollow\nluke_thompson._\nLuke Thompson\nFollow\ntheupsstore\nThe UPS Store\nFollow\nroberthalf\nRobert Half\nFollow\nsurveymonkey\nSurveyMonkey\nFollow\nnortonsecurity\nNorton\nFollow\nmcafee\nMcAfee\nFollow\namazonunpacked\nAmazon Unpacked\nFollow\nrandstadusa\nrandstad usa\nFollow\nziprecruiter\nZipRecruiter\nFollow\namazonstorejobs\nAmazo",
         "https://hiring.amazon.com/%22",
         "2025-09-05T15:06:27Z"
        ],
        [
         "2",
         "Amazon Jobs Overview",
         null,
         null,
         "https://hiring.amazon.com/job-opportunities",
         "Open side menu.\nEnglish\nInformation\nHey! We're experiencing some technical difficulties around the work authorization and Form I-9 at the moment, but don't worry—our team is working to fix it. Thanks for your patience while we sort this out!\nDismiss announcement\nJobs Overview\nAmazon has hourly jobs for everyone. Join one of the many teams that are the dedicated workforce bringing smiles to our customers every day – an Amazon Associate. Choose from a variety of roles, most with shifts and schedules that work with your life, so find the one that’s right for you and begin your Amazon journey today.\nAmazon Warehouses\nYou’ll be part of the team working in one of the many types of Amazon warehouses – the epicenters of our operations, the place where customer orders begin their journey from click",
         "https://hiring.amazon.com/%22",
         "2025-09-05T15:06:55Z"
        ],
        [
         "3",
         "Job Search",
         null,
         null,
         "https://hiring.amazon.com/app#/jobSearch",
         null,
         "https://hiring.amazon.com/%22",
         "2025-09-05T15:07:22Z"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>application_link</th>\n",
       "      <th>description_snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>scraped_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contact us.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.amazondelivers.jobs/contactus</td>\n",
       "      <td>None</td>\n",
       "      <td>https://hiring.amazon.com/%22</td>\n",
       "      <td>2025-09-05T15:06:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instagraminstagram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.instagram.com/amazonjobs/</td>\n",
       "      <td>Log In\\nSign Up\\namazonjobs\\nAmazon Jobs\\n153 ...</td>\n",
       "      <td>https://hiring.amazon.com/%22</td>\n",
       "      <td>2025-09-05T15:06:27Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Jobs Overview</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://hiring.amazon.com/job-opportunities</td>\n",
       "      <td>Open side menu.\\nEnglish\\nInformation\\nHey! We...</td>\n",
       "      <td>https://hiring.amazon.com/%22</td>\n",
       "      <td>2025-09-05T15:06:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Search</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://hiring.amazon.com/app#/jobSearch</td>\n",
       "      <td>None</td>\n",
       "      <td>https://hiring.amazon.com/%22</td>\n",
       "      <td>2025-09-05T15:07:22Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title location company  \\\n",
       "0           contact us.     None    None   \n",
       "1    instagraminstagram     None    None   \n",
       "2  Amazon Jobs Overview     None    None   \n",
       "3            Job Search     None    None   \n",
       "\n",
       "                              application_link  \\\n",
       "0    https://www.amazondelivers.jobs/contactus   \n",
       "1        https://www.instagram.com/amazonjobs/   \n",
       "2  https://hiring.amazon.com/job-opportunities   \n",
       "3     https://hiring.amazon.com/app#/jobSearch   \n",
       "\n",
       "                                 description_snippet  \\\n",
       "0                                               None   \n",
       "1  Log In\\nSign Up\\namazonjobs\\nAmazon Jobs\\n153 ...   \n",
       "2  Open side menu.\\nEnglish\\nInformation\\nHey! We...   \n",
       "3                                               None   \n",
       "\n",
       "                          source            scraped_at  \n",
       "0  https://hiring.amazon.com/%22  2025-09-05T15:06:04Z  \n",
       "1  https://hiring.amazon.com/%22  2025-09-05T15:06:27Z  \n",
       "2  https://hiring.amazon.com/%22  2025-09-05T15:06:55Z  \n",
       "3  https://hiring.amazon.com/%22  2025-09-05T15:07:22Z  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes:\n",
      " - Detected site: generic\n",
      " - Parsed 4 rows\n",
      " - Enriched with description snippets\n"
     ]
    }
   ],
   "source": [
    "final, df = run_scrape(\"https://hiring.amazon.com/%22\", limit = 10)\n",
    "display(df.head())\n",
    "print(\"\\nNotes:\", *final.get(\"notes\", []), sep=\"\\n - \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
